{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b22ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec1d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'C:\\Users\\jdrij\\OneDrive\\Bureaublad\\Master\\ML_Github\\ML4QS-project\\data\\train_df.csv')\n",
    "# test_df = pd.read_csv(r'C:\\Users\\jdrij\\OneDrive\\Bureaublad\\Master\\ML_Github\\ML4QS-project\\data\\test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc379fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(df, n_groups=5, val_group=0):\n",
    "    grouped = []\n",
    "\n",
    "    for label in df['transport_mode'].unique():\n",
    "        df_label = df[df['transport_mode'] == label].copy()\n",
    "        df_label = df_label.sort_values(by='Time').reset_index(drop=True)  # <-- chronologische volgorde\n",
    "\n",
    "        # Verdeel in ongeveer gelijke groepen\n",
    "        split_groups = np.array_split(df_label, n_groups)\n",
    "        for i, group in enumerate(split_groups):\n",
    "            group['group'] = i\n",
    "            grouped.append(group)\n",
    "\n",
    "    df_grouped = pd.concat(grouped).reset_index(drop=True)\n",
    "\n",
    "    val_set = df_grouped[df_grouped['group'] == val_group]\n",
    "    train_set = df_grouped[df_grouped['group'] != val_group]\n",
    "\n",
    "    return train_set.drop(columns=['group']), val_set.drop(columns=['group'])\n",
    "\n",
    "# Voorbeeld gebruik:\n",
    "train_df_hyper, val_df_hyper = split_train_val(train_df, val_group=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6896688",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_hyper.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aa8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_hyper.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db09c54",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 1: Voorbereiden van data\n",
    "# -----------------------------\n",
    "X_train_xgb = train_df_hyper.drop(columns=['transport_mode', 'Time'])\n",
    "y_train_xgb = train_df_hyper['transport_mode']\n",
    "\n",
    "X_val_xgb = val_df_hyper.drop(columns=['transport_mode', 'Time'])\n",
    "y_val_xgb = val_df_hyper['transport_mode']\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 2: Encode labels\n",
    "# -----------------------------\n",
    "le_xgb = LabelEncoder()\n",
    "y_train_enc_xgb = le_xgb.fit_transform(y_train_xgb)\n",
    "y_val_enc_xgb = le_xgb.transform(y_val_xgb)\n",
    "\n",
    "print(\"Label mapping (XGB):\", dict(zip(le_xgb.classes_, le_xgb.transform(le_xgb.classes_))))\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 3: Combineer train en val\n",
    "# -----------------------------\n",
    "X_combined_xgb = pd.concat([X_train_xgb, X_val_xgb], axis=0)\n",
    "y_combined_xgb = np.concatenate([y_train_enc_xgb, y_val_enc_xgb])\n",
    "\n",
    "val_fold_xgb = [-1] * len(X_train_xgb) + [0] * len(X_val_xgb)\n",
    "ps_xgb = PredefinedSplit(val_fold_xgb)\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 4: Hyperparameterraster\n",
    "# -----------------------------\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500, 700, 1000],\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'subsample': [0.5, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 5: Grid Search\n",
    "# -----------------------------\n",
    "model_xgb = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    estimator=model_xgb,\n",
    "    param_grid=param_grid_xgb,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=ps_xgb,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_search_xgb.fit(X_combined_xgb, y_combined_xgb)\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 6: Toon train en val scores\n",
    "# -----------------------------\n",
    "results_xgb = pd.DataFrame(grid_search_xgb.cv_results_)\n",
    "\n",
    "print(\"\\nTrain/Validation scores per parameter set (XGB):\\n\")\n",
    "for i in range(len(results_xgb)):\n",
    "    params = results_xgb.loc[i, 'params']\n",
    "    train_acc = results_xgb.loc[i, 'mean_train_score']\n",
    "    val_acc = results_xgb.loc[i, 'mean_test_score']\n",
    "    print(f\"Parameters: {params}\")\n",
    "    print(f\"→ Train accuracy: {train_acc:.4f}, Val accuracy: {val_acc:.4f}\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Beste combinatie + accuracies\n",
    "# -----------------------------\n",
    "print(\"Beste hyperparameters (XGB):\")\n",
    "print(grid_search_xgb.best_params_)\n",
    "\n",
    "best_params_xgb = grid_search_xgb.best_params_\n",
    "best_train_acc_xgb = results_xgb.loc[grid_search_xgb.best_index_, 'mean_train_score']\n",
    "best_val_acc_xgb = results_xgb.loc[grid_search_xgb.best_index_, 'mean_test_score']\n",
    "\n",
    "print(\"\\nBeste hyperparameters (XGB):\")\n",
    "print(best_params_xgb)\n",
    "print(f\"→ Train Accuracy:      {best_train_acc_xgb:.4f}\")\n",
    "print(f\"→ Validation Accuracy: {best_val_acc_xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4548b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_save_xgb = results_xgb[[\n",
    "    'params',\n",
    "    'mean_train_score',\n",
    "    'mean_test_score',  # test = validation in GridSearchCV\n",
    "    'rank_test_score'\n",
    "]]\n",
    "\n",
    "# Expand the 'params' dictionary into separate columns\n",
    "params_df_xgb = results_xgb['params'].apply(pd.Series)\n",
    "\n",
    "# Combine everything into one DataFrame\n",
    "full_results_df_xgb = pd.concat([\n",
    "    params_df_xgb,\n",
    "    results_to_save_xgb.drop(columns=['params'])\n",
    "], axis=1)\n",
    "\n",
    "# Rename for clarity\n",
    "full_results_df_xgb.rename(columns={\n",
    "    'mean_train_score': 'train_accuracy',\n",
    "    'mean_test_score': 'val_accuracy'\n",
    "}, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "full_results_df_xgb.to_csv(\"xgb_train_val_accuracy_results.csv\", index=False)\n",
    "\n",
    "print(\"Train and validation accuracy results saved to 'xgb_train_val_accuracy_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c37a03e",
   "metadata": {},
   "source": [
    "Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 1: Voorbereiden van data\n",
    "# -----------------------------\n",
    "X_train_rf = train_df_hyper.drop(columns=['transport_mode', 'Time'])\n",
    "y_train_rf = train_df_hyper['transport_mode']\n",
    "\n",
    "X_val_rf = val_df_hyper.drop(columns=['transport_mode', 'Time'])\n",
    "y_val_rf = val_df_hyper['transport_mode']\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 2: Encode labels\n",
    "# -----------------------------\n",
    "le_rf = LabelEncoder()\n",
    "y_train_enc_rf = le_rf.fit_transform(y_train_rf)\n",
    "y_val_enc_rf = le_rf.transform(y_val_rf)\n",
    "\n",
    "print(\"Label mapping (RF):\", dict(zip(le_rf.classes_, le_rf.transform(le_rf.classes_))))\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 3: Combineer train en val\n",
    "# -----------------------------\n",
    "X_combined_rf = pd.concat([X_train_rf, X_val_rf], axis=0)\n",
    "y_combined_rf = np.concatenate([y_train_enc_rf, y_val_enc_rf])\n",
    "\n",
    "val_fold_rf = [-1] * len(X_train_rf) + [0] * len(X_val_rf)\n",
    "ps_rf = PredefinedSplit(val_fold_rf)\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 4: Hyperparameterraster\n",
    "# -----------------------------\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300, 500, 700, 1000],\n",
    "    'max_depth': [None,5, 10, 20, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', 0.2, 0.5, 0.8],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 5: Grid Search\n",
    "# -----------------------------\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=model_rf,\n",
    "    param_grid=param_grid_rf,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=ps_rf,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(X_combined_rf, y_combined_rf)\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 6: Resultaten tonen\n",
    "# -----------------------------\n",
    "results_rf = pd.DataFrame(grid_search_rf.cv_results_)\n",
    "\n",
    "print(\"\\nTrain/Validation scores per parameter set (RF):\\n\")\n",
    "for i in range(len(results_rf)):\n",
    "    params = results_rf.loc[i, 'params']\n",
    "    train_acc = results_rf.loc[i, 'mean_train_score']\n",
    "    val_acc = results_rf.loc[i, 'mean_test_score']\n",
    "    print(f\"Parameters: {params}\")\n",
    "    print(f\"→ Train accuracy: {train_acc:.4f}, Val accuracy: {val_acc:.4f}\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Beste combinatie + accuracies\n",
    "# -----------------------------\n",
    "print(\"Beste hyperparameters (RF):\")\n",
    "print(grid_search_rf.best_params_)\n",
    "\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "best_train_acc_rf = results_rf.loc[grid_search_rf.best_index_, 'mean_train_score']\n",
    "best_val_acc_rf = results_rf.loc[grid_search_rf.best_index_, 'mean_test_score']\n",
    "\n",
    "print(\"\\nBeste hyperparameters (Random Forest):\")\n",
    "print(best_params_rf)\n",
    "print(f\"→ Train Accuracy:      {best_train_acc_rf:.4f}\")\n",
    "print(f\"→ Validation Accuracy: {best_val_acc_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c67080",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_save_rf = results_rf[[\n",
    "    'params',\n",
    "    'mean_train_score',\n",
    "    'mean_test_score',  # test = validation in GridSearchCV\n",
    "    'rank_test_score'\n",
    "]]\n",
    "\n",
    "# Expand the 'params' dictionary into separate columns\n",
    "params_df_rf = results_rf['params'].apply(pd.Series)\n",
    "\n",
    "# Combine everything into one DataFrame\n",
    "full_results_df_rf = pd.concat([\n",
    "    params_df_rf,\n",
    "    results_to_save_rf.drop(columns=['params'])\n",
    "], axis=1)\n",
    "\n",
    "# Rename for clarity\n",
    "full_results_df_rf.rename(columns={\n",
    "    'mean_train_score': 'train_accuracy',\n",
    "    'mean_test_score': 'val_accuracy'\n",
    "}, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "full_results_df_rf.to_csv(\"rf_train_val_accuracy_results.csv\", index=False)\n",
    "\n",
    "print(\"Train and validation accuracy results saved to 'rf_train_val_accuracy_results.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2a3295",
   "metadata": {},
   "source": [
    "Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab14b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 1: Voorbereiden van data\n",
    "# -----------------------------\n",
    "X_train_cb = train_df_hyper.drop(columns=['transport_mode', 'Time'])\n",
    "y_train_cb = train_df_hyper['transport_mode']\n",
    "\n",
    "X_val_cb = val_df_hyper.drop(columns=['transport_mode', 'Time'])\n",
    "y_val_cb = val_df_hyper['transport_mode']\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 2: Encode labels\n",
    "# -----------------------------\n",
    "le_cb = LabelEncoder()\n",
    "y_train_enc_cb = le_cb.fit_transform(y_train_cb)\n",
    "y_val_enc_cb = le_cb.transform(y_val_cb)\n",
    "\n",
    "print(\"Label mapping (CatBoost):\", dict(zip(le_cb.classes_, le_cb.transform(le_cb.classes_))))\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 3: Combineer train en val\n",
    "# -----------------------------\n",
    "X_combined_cb = pd.concat([X_train_cb, X_val_cb], axis=0)\n",
    "y_combined_cb = np.concatenate([y_train_enc_cb, y_val_enc_cb])\n",
    "\n",
    "val_fold_cb = [-1] * len(X_train_cb) + [0] * len(X_val_cb)\n",
    "ps_cb = PredefinedSplit(val_fold_cb)\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 4: Hyperparameterraster\n",
    "# -----------------------------\n",
    "param_grid_cb = {\n",
    "    'iterations': [200, 300, 500, 700],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'depth': [4, 6, 8, 10]\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 5: Grid Search\n",
    "# -----------------------------\n",
    "model_cb = CatBoostClassifier(\n",
    "    verbose=0,\n",
    "    random_state=42,\n",
    "    loss_function='MultiClass'\n",
    ")\n",
    "\n",
    "grid_search_cb = GridSearchCV(\n",
    "    estimator=model_cb,\n",
    "    param_grid=param_grid_cb,\n",
    "    scoring='accuracy',\n",
    "    cv=ps_cb,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_search_cb.fit(X_combined_cb, y_combined_cb)\n",
    "\n",
    "# -----------------------------\n",
    "# Stap 6: Resultaten tonen\n",
    "# -----------------------------\n",
    "results_cb = pd.DataFrame(grid_search_cb.cv_results_)\n",
    "\n",
    "print(\"\\nTrain/Validation scores per parameter set (CatBoost):\\n\")\n",
    "for i in range(len(results_cb)):\n",
    "    params = results_cb.loc[i, 'params']\n",
    "    train_acc = results_cb.loc[i, 'mean_train_score']\n",
    "    val_acc = results_cb.loc[i, 'mean_test_score']\n",
    "    print(f\"Parameters: {params}\")\n",
    "    print(f\"→ Train accuracy: {train_acc:.4f}, Val accuracy: {val_acc:.4f}\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Beste combinatie + accuracies\n",
    "# -----------------------------\n",
    "print(\"Beste hyperparameters (CatBoost):\")\n",
    "print(grid_search_cb.best_params_)\n",
    "\n",
    "best_params_cb = grid_search_cb.best_params_\n",
    "best_train_acc_cb = results_cb.loc[grid_search_cb.best_index_, 'mean_train_score']\n",
    "best_val_acc_cb = results_cb.loc[grid_search_cb.best_index_, 'mean_test_score']\n",
    "\n",
    "print(\"\\nBeste hyperparameters (CatBoost):\")\n",
    "print(best_params_cb)\n",
    "print(f\"→ Train Accuracy:      {best_train_acc_cb:.4f}\")\n",
    "print(f\"→ Validation Accuracy: {best_val_acc_cb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a61aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_save_cb = results_cb[[\n",
    "    'params',\n",
    "    'mean_train_score',\n",
    "    'mean_test_score',  # test = validation in GridSearchCV\n",
    "    'rank_test_score'\n",
    "]]\n",
    "\n",
    "# Expand the 'params' dictionary into separate columns\n",
    "params_df_cb = results_cb['params'].apply(pd.Series)\n",
    "\n",
    "# Combine everything into one DataFrame\n",
    "full_results_df_cb = pd.concat([\n",
    "    params_df_cb,\n",
    "    results_to_save_cb.drop(columns=['params'])\n",
    "], axis=1)\n",
    "\n",
    "# Rename for clarity\n",
    "full_results_df_cb.rename(columns={\n",
    "    'mean_train_score': 'train_accuracy',\n",
    "    'mean_test_score': 'val_accuracy'\n",
    "}, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "full_results_df_cb.to_csv(\"cb_train_val_accuracy_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d150160e",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b004672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Prepare data\n",
    "# -----------------------------\n",
    "X_train_knn = train_df_hyper.drop(columns=['transport_mode', 'Time'])\n",
    "y_train_knn = train_df_hyper['transport_mode']\n",
    "\n",
    "X_val_knn = val_df_hyper.drop(columns=['transport_mode', 'Time'])\n",
    "y_val_knn = val_df_hyper['transport_mode']\n",
    "\n",
    "# Encode labels\n",
    "le_knn = LabelEncoder()\n",
    "y_train_enc_knn = le_knn.fit_transform(y_train_knn)\n",
    "y_val_enc_knn = le_knn.transform(y_val_knn)\n",
    "\n",
    "# Combine and scale\n",
    "X_combined_knn = pd.concat([X_train_knn, X_val_knn], axis=0)\n",
    "y_combined_knn = np.concatenate([y_train_enc_knn, y_val_enc_knn])\n",
    "\n",
    "scaler_knn = StandardScaler()\n",
    "X_combined_knn_scaled = scaler_knn.fit_transform(X_combined_knn)\n",
    "\n",
    "# Predefined split\n",
    "val_fold_knn = [-1] * len(X_train_knn) + [0] * len(X_val_knn)\n",
    "ps_knn = PredefinedSplit(val_fold_knn)\n",
    "\n",
    "# -----------------------------\n",
    "# Define hyperparameter grid\n",
    "# -----------------------------\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # Manhattan and Euclidean\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Grid Search\n",
    "# -----------------------------\n",
    "model_knn = KNeighborsClassifier()\n",
    "grid_search_knn = GridSearchCV(\n",
    "    estimator=model_knn,\n",
    "    param_grid=param_grid_knn,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=ps_knn,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_search_knn.fit(X_combined_knn_scaled, y_combined_knn)\n",
    "\n",
    "# -----------------------------\n",
    "# Results\n",
    "# -----------------------------\n",
    "results_knn = pd.DataFrame(grid_search_knn.cv_results_)\n",
    "\n",
    "# Best parameters + accuracies\n",
    "best_params_knn = grid_search_knn.best_params_\n",
    "best_train_acc_knn = results_knn.loc[grid_search_knn.best_index_, 'mean_train_score']\n",
    "best_val_acc_knn = results_knn.loc[grid_search_knn.best_index_, 'mean_test_score']\n",
    "\n",
    "print(\"\\nBeste hyperparameters (KNN):\")\n",
    "print(best_params_knn)\n",
    "print(f\"→ Train Accuracy:      {best_train_acc_knn:.4f}\")\n",
    "print(f\"→ Validation Accuracy: {best_val_acc_knn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ba3bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_save_knn = results_knn[[\n",
    "    'params',\n",
    "    'mean_train_score',\n",
    "    'mean_test_score',  # test = validation in GridSearchCV\n",
    "    'rank_test_score'\n",
    "]]\n",
    "\n",
    "# Expand the 'params' dictionary into separate columns\n",
    "params_df_knn = results_knn['params'].apply(pd.Series)\n",
    "\n",
    "# Combine everything into one DataFrame\n",
    "full_results_df_knn = pd.concat([\n",
    "    params_df_knn,\n",
    "    results_to_save_knn.drop(columns=['params'])\n",
    "], axis=1)\n",
    "\n",
    "# Rename for clarity\n",
    "full_results_df_knn.rename(columns={\n",
    "    'mean_train_score': 'train_accuracy',\n",
    "    'mean_test_score': 'val_accuracy'\n",
    "}, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "full_results_df_knn.to_csv(\"knn_train_val_accuracy_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b5e54",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd42138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Prepare data\n",
    "# -----------------------------\n",
    "X_train_logreg = train_df_hyper.drop(columns=['transport_mode', 'Time'])\n",
    "y_train_logreg = train_df_hyper['transport_mode']\n",
    "\n",
    "X_val_logreg = val_df_hyper.drop(columns=['transport_mode', 'Time'])\n",
    "y_val_logreg = val_df_hyper['transport_mode']\n",
    "\n",
    "# Encode target\n",
    "le_logreg = LabelEncoder()\n",
    "y_train_enc_logreg = le_logreg.fit_transform(y_train_logreg)\n",
    "y_val_enc_logreg = le_logreg.transform(y_val_logreg)\n",
    "\n",
    "# Combine train and val\n",
    "X_combined_logreg = pd.concat([X_train_logreg, X_val_logreg], axis=0)\n",
    "y_combined_logreg = np.concatenate([y_train_enc_logreg, y_val_enc_logreg])\n",
    "\n",
    "# Scaling\n",
    "scaler_logreg = StandardScaler()\n",
    "X_combined_scaled_logreg = scaler_logreg.fit_transform(X_combined_logreg)\n",
    "\n",
    "# Predefined split\n",
    "val_fold_logreg = [-1] * len(X_train_logreg) + [0] * len(X_val_logreg)\n",
    "ps_logreg = PredefinedSplit(val_fold_logreg)\n",
    "\n",
    "# -----------------------------\n",
    "# Define hyperparameter grid\n",
    "# -----------------------------\n",
    "param_grid_logreg = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [500, 1000]\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Grid Search\n",
    "# -----------------------------\n",
    "model_logreg = LogisticRegression()\n",
    "grid_search_logreg = GridSearchCV(\n",
    "    estimator=model_logreg,\n",
    "    param_grid=param_grid_logreg,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=ps_logreg,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_search_logreg.fit(X_combined_scaled_logreg, y_combined_logreg)\n",
    "\n",
    "# -----------------------------\n",
    "# Results\n",
    "# -----------------------------\n",
    "results_logreg = pd.DataFrame(grid_search_logreg.cv_results_)\n",
    "\n",
    "# Best parameters + train/val accuracy\n",
    "best_params_logreg = grid_search_logreg.best_params_\n",
    "best_train_acc_logreg = results_logreg.loc[grid_search_logreg.best_index_, 'mean_train_score']\n",
    "best_val_acc_logreg = results_logreg.loc[grid_search_logreg.best_index_, 'mean_test_score']\n",
    "\n",
    "print(\"\\nBeste hyperparameters (Logistic Regression):\")\n",
    "print(best_params_logreg)\n",
    "print(f\"→ Train Accuracy:      {best_train_acc_logreg:.4f}\")\n",
    "print(f\"→ Validation Accuracy: {best_val_acc_logreg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f84a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_save_logreg = results_logreg[[\n",
    "    'params',\n",
    "    'mean_train_score',\n",
    "    'mean_test_score',  # test = validation in GridSearchCV\n",
    "    'rank_test_score'\n",
    "]]\n",
    "\n",
    "# Expand the 'params' dictionary into separate columns\n",
    "params_df_logreg = results_logreg['params'].apply(pd.Series)\n",
    "\n",
    "# Combine everything into one DataFrame\n",
    "full_results_df_logreg = pd.concat([\n",
    "    params_df_logreg,\n",
    "    results_to_save_logreg.drop(columns=['params'])\n",
    "], axis=1)\n",
    "\n",
    "# Rename for clarity\n",
    "full_results_df_logreg.rename(columns={\n",
    "    'mean_train_score': 'train_accuracy',\n",
    "    'mean_test_score': 'val_accuracy'\n",
    "}, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "full_results_df_logreg.to_csv(\"logreg_train_val_accuracy_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
